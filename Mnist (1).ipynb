{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G0PA8zlIsXnt"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2an-Sn2sqUv",
        "outputId": "c8fb2394-afeb-4c78-f5fc-ba6bf124cbe2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 30.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.06MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.11MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.52MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewh4cz-vDNW",
        "outputId": "b94e66a7-8035-4aef-d0bb-e54ff90be63f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGRfNA6gvKLb",
        "outputId": "4bdcd878-5ebc-4778-a19f-8e83642f92bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test': DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
        "}"
      ],
      "metadata": {
        "id": "ySe9E1ynvVae"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1,320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "xodJByfJv279"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} \"\n",
        "                  f\"({100. * batch_idx / len(loaders['train']):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "\n",
        "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} \"\n",
        "          f\"({100. * correct / len(loaders['test'].dataset):.0f}%)\\n\")"
      ],
      "metadata": {
        "id": "aLOeBIYoztgc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlHkCn512o5w",
        "outputId": "8b3f6cfa-e597-4f81-c2c9-a2191253d197"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303339\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.207571\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.752109\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.134335\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.898185\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.871289\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.670397\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.825730\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.702639\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.687223\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.460911\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.617886\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.595688\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.530185\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.487166\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.423397\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.445785\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.692112\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.558272\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.364419\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.378569\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.565937\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.398798\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.475551\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.304926\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.313133\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.275266\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.443008\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.373525\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.356159\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9544/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.520249\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.515878\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.351628\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.274426\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.347095\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.285450\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.350816\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.429215\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.368083\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.381327\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.210528\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.336112\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.352516\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.423992\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.222713\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.181368\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.280334\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.282666\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.301800\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.456044\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.386326\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.151984\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.249871\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.301545\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.237475\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.213427\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.216607\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.263452\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.402905\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.222394\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9685/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.298537\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.418571\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.213346\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.319006\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.148546\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.261149\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.283017\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.254476\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.256732\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.398828\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.195804\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.243672\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.273908\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.212332\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.240764\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.227445\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.247481\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.365524\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.181955\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.232862\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.235759\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.227744\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.133467\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.194824\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.285181\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.387265\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.190771\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.288700\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.250310\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.277228\n",
            "\n",
            "Test set: Average loss: 0.0008, Accuracy: 9745/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.302877\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.204318\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.328254\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.377364\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.192915\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.286136\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.372166\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.235717\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.197416\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.221605\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.201231\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.209312\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.115707\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.204416\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.265451\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.149273\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.220715\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.205590\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.260133\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.201081\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.218778\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.171858\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.179028\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.160987\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.285670\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.216599\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.385847\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.110401\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.203246\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.134396\n",
            "\n",
            "Test set: Average loss: 0.0007, Accuracy: 9774/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.215429\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.177809\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.214969\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.077453\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.134331\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.271924\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.075002\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.336972\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.172135\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.169294\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.209255\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.188933\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.220483\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.190042\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.110734\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.109375\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.203934\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.184354\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.112383\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.132174\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.145297\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.163541\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.160838\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.096272\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.220662\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.199247\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.242569\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.115743\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.246318\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.158507\n",
            "\n",
            "Test set: Average loss: 0.0006, Accuracy: 9794/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.170518\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.174353\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.343887\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.109665\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.127930\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.138338\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.244478\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.304008\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.141210\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.098413\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.224597\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.245638\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.200073\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.223926\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.227801\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.221502\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.114858\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.236642\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.113819\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.355190\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.141692\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.166183\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.091634\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.187786\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.229980\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.107526\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.156691\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.495458\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.160432\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.200401\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9832/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.246443\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.130616\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.189532\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.197877\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.259987\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.035628\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.079036\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.086472\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.194980\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.156173\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.156828\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.186633\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.142058\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.147940\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.189079\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.284645\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.315048\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.096147\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.120267\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.118239\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.127061\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.242517\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.354671\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.238341\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.170024\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.193218\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.129682\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.218123\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.136661\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.280244\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9847/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.260908\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.092206\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.187107\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.146369\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.145803\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.241914\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.216986\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.054844\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.371248\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.187466\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.123873\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.317782\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.184002\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.093658\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.223053\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.258201\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.222944\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.070030\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.204929\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.098707\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.299125\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.313506\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.267847\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.128329\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.171496\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.187254\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.083062\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.118018\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.187394\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.179156\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9843/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.101488\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.238240\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.111975\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.153559\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.115545\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.168650\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.149665\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.103290\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.204641\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.164210\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.120454\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.163350\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.157301\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.111850\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.284437\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.072181\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.228338\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.059078\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.171869\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.156852\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.181890\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.123891\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.140641\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.119091\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.131220\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.092515\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.275621\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.133265\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.106992\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.303382\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9853/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.213873\n",
            "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.141360\n",
            "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.164788\n",
            "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.172531\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.195062\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.167339\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.119593\n",
            "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.104616\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.086595\n",
            "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.189047\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.099865\n",
            "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.175150\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.403548\n",
            "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.154996\n",
            "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.186793\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.183593\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.159335\n",
            "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.117852\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.264235\n",
            "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.206758\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.216053\n",
            "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.133906\n",
            "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.064530\n",
            "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.201084\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.112847\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.226981\n",
            "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.221504\n",
            "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.142399\n",
            "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.164485\n",
            "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.030990\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 9865/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "data, target = test_data[1]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "pred = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(pred)\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "M3Rvut_A81l7",
        "outputId": "22d5be15-7dbe-44d0-9c7e-0bb7b47384e5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 482);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}